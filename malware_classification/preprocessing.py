import pandas as pd
from pandas import DataFrame
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split


def get_dataset() -> (DataFrame, DataFrame):
    with (open('api-call-traces/api_trace.csv', 'r') as csvfile,
          open('api-call-traces/api_trace_labels.txt', 'r') as labels):
        trace = remove_sequences(csvfile.read().splitlines())
        vectorizer = CountVectorizer(ngram_range=(1, 2))
        count_vector = vectorizer.fit_transform(trace)

        df = DataFrame(
            data=count_vector.toarray(),
            columns=vectorizer.vocabulary
        )
        df['label'] = labels.read().splitlines()
        return train_test_split(df, test_size=0.3, random_state=43)


def get_dataset_lstm() -> (DataFrame, DataFrame):
    df = pd.read_csv('api-call-traces/api_trace.txt')
    df = pd.get_dummies(df, columns=df.columns)
    with open('api-call-traces/api_trace_labels.txt', 'r') as labels:
        df['label'] = labels.read().splitlines()

    return train_test_split(df, test_size=0.2, random_state=43)


def remove_sequences(csvfile: list[str]):
    for line in range(len(csvfile)):
        entries = csvfile[line].split(',')
        new_entries = []
        for i in range(1, len(entries)):
            if entries[i] != entries[i - 1]:
                new_entries.append(entries[i])
        csvfile[line] = ','.join(new_entries)
    return csvfile


if __name__ == '__main__':
    train, test = get_dataset()
    print(train.head(5).to_string())