import os

import seaborn as sb
import skops.io as sio
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier

import preprocessing

plots_dir = os.path.join(os.path.dirname(__file__), 'plots')

classifiers = {
    "Naive Bayes": MultinomialNB(),
    "Logistic Regression": LogisticRegression(max_iter=2000, n_jobs=2, random_state=43),
    "K-Nearest Neighbors": KNeighborsClassifier(n_jobs=2),
    "Random Forest": RandomForestClassifier(n_estimators=200, n_jobs=2, random_state=43)
}


# noinspection DuplicatedCode
def plot_confusion_matrix(y_true, y_pred, labels, model_name: str):
    m = confusion_matrix(y_true, y_pred, labels=labels)
    ax = sb.heatmap(m, annot=True, cmap='Blues', fmt='g')
    ax.set_title(f'{model_name} Confusion matrix')
    ax.set_xlabel('Predicted Values')
    ax.set_ylabel('True Values')
    ax.set_xticklabels(labels)
    ax.set_yticklabels(labels)

    if not os.path.isdir(plots_dir):
        os.mkdir(plots_dir)
    plt.savefig(os.path.join(plots_dir, f"{model_name}.png"))
    plt.show()


def persist_model(model):
    sio.dump(model, os.path.join(os.path.dirname(__file__), 'model.skops'))


def test_models():
    print("Preprocessing dataset...")
    train, test = preprocessing.get_dataset()

    x_train = train.drop('label', axis=1)
    y_train = train['label']
    x_test = test.drop('label', axis=1)
    y_test = test['label']

    x_train_scaled, x_test_scaled = preprocessing.scale_data(x_train, x_test)

    best_f1 = 0
    best_name = ""
    for name, classifier in classifiers.items():
        print(f"Training {name}...")
        classifier.fit(x_train_scaled if name == "Logistic Regression" or name == "SGD" else x_train, y_train)

        y_pred = classifier.predict(x_test_scaled if name == "Logistic Regression" or name == "SGD" else x_test)
        f1 = f1_score(y_test, y_pred, average='macro')
        print(f"{name} F1-Score: {f1}")
        plot_confusion_matrix(y_test, y_pred, y_test.unique(), name)

        if f1 > best_f1:
            best_f1 = f1
            best_name = name

    print(f"Persisting {best_name} model")
    persist_model(classifiers[best_name])


if __name__ == '__main__':
    test_models()